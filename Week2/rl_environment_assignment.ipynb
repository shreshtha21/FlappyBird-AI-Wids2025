{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12aac321",
   "metadata": {},
   "source": [
    "# Week-2 Assignment: Environment Design & Validation (RL)\n",
    "\n",
    "This notebook focuses **only on environment design**, not training agents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bd61a2",
   "metadata": {},
   "source": [
    "## Task 0: Imports & Seeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c868e558",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# TODO: Do not modify this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7626eabc",
   "metadata": {},
   "source": [
    "## Task 1: Implement the Environment (MDP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c1cdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlappyEnv:\n",
    "    def __init__(self, gravity=1.0):\n",
    "        \"\"\"\n",
    "        TODO:\n",
    "        - Initialize all environment constants\n",
    "        - Store gravity\n",
    "        - Do NOT use any RL library\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        TODO:\n",
    "        - Reset bird position and velocity\n",
    "        - Reset pipe position and gap location\n",
    "        - Set done = False\n",
    "        - Return initial state\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def _get_state(self):\n",
    "        \"\"\"\n",
    "        TODO:\n",
    "        - State must be:\n",
    "          (bird_y, bird_velocity, distance_to_pipe, gap_offset)\n",
    "        - Return as numpy array\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        action ∈ {0, 1}\n",
    "        0 -> do nothing\n",
    "        1 -> flap\n",
    "\n",
    "        TODO:\n",
    "        - Apply physics\n",
    "        - Update positions\n",
    "        - Check collisions\n",
    "        - Compute reward\n",
    "        - Return (next_state, reward, done)\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eca78f0",
   "metadata": {},
   "source": [
    "## Task 2: Markov Property Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0439af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_markov_sufficient(env, state, action=0, trials=10):\n",
    "    \"\"\"\n",
    "    TODO:\n",
    "    - Reset environment multiple times\n",
    "    - Force the same state\n",
    "    - Take the same action\n",
    "    - If next states differ → return False\n",
    "    - Else return True\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fb82d9",
   "metadata": {},
   "source": [
    "## Task 3: Discretization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc1b3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretize_state(state):\n",
    "    \"\"\"\n",
    "    TODO:\n",
    "    Discretize state using:\n",
    "    - bird_y / gap_offset: below, inside, above\n",
    "    - velocity: falling fast, slow, rising\n",
    "    - distance_to_pipe: near, far\n",
    "    Return a tuple of discrete values\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8bbba7",
   "metadata": {},
   "source": [
    "## Task 4: Discrete State Space Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e03f96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# - Define number of bins per dimension\n",
    "# - Compute total discrete states\n",
    "# - Assert total_states <= 10000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee236b8c",
   "metadata": {},
   "source": [
    "## Task 5: Reward Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb65778",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_reward(info):\n",
    "    \"\"\"\n",
    "    TODO:\n",
    "    - +10 for passing pipe\n",
    "    - -50 for death\n",
    "    - 0 otherwise\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def dense_reward(info):\n",
    "    \"\"\"\n",
    "    TODO:\n",
    "    - Small positive reward for staying alive\n",
    "    - Large negative reward for death\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def shaped_reward(info):\n",
    "    \"\"\"\n",
    "    TODO:\n",
    "    - Start from dense reward\n",
    "    - Penalize distance from gap center slightly\n",
    "    - Shaping must not dominate sparse reward\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c694e5",
   "metadata": {},
   "source": [
    "## Task 6: Random Policy Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7093744f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_random_policy(env, episodes=500):\n",
    "    \"\"\"\n",
    "    TODO:\n",
    "    - Run random actions\n",
    "    - Track episode lengths & rewards\n",
    "    - Print statistics\n",
    "    - Warn if environment is too easy or too hard\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af494ff7",
   "metadata": {},
   "source": [
    "## Task 7: Environment Stress Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9915647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# - Test random policy under gravity × {0.8, 1.0, 1.2}\n",
    "# - Store average episode length\n",
    "# - Plot results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388957ae",
   "metadata": {},
   "source": [
    "## Submission Checklist\n",
    "- All TODOs implemented\n",
    "- No RL training code\n",
    "- Environment deterministic\n",
    "- Random policy runs without crashing\n",
    "- Stress test plot included"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
